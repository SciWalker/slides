import os
from typing import TypedDict
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.chat_models import ChatOllama
from langgraph.graph import StateGraph, END

# --- LLM Definition ---
# This script now uses ChatOllama to connect to a local Ollama server.
# Make sure you have Ollama running and the 'gpt:oss' model pulled.
# You can pull the model by running: `ollama pull gpt:oss`
try:
    llm = ChatOllama(model="gpt-oss")
except Exception as e:
    print(f"Error initializing Ollama: {e}")
    print("Please ensure Ollama is running and the 'gpt:oss' model is available.")
    exit()

# --- Graph State Definition ---
class GraphState(TypedDict):
    markdown_script: str
    presentation_html: str
    feedback: str
    revision_count: int

# --- Node Definitions ---

def generate_presentation_node(state: GraphState):
    """
    Generates the initial Reveal.js presentation from the markdown script using an LLM.
    """
    print("--- ğŸ§  Node: generate_presentation ---")
    markdown = state['markdown_script']
    
    prompt = PromptTemplate(
        template="""You are an expert at creating web presentations.
Convert the following markdown script into a complete, single-file Reveal.js HTML presentation.
The HTML must be fully functional, including the necessary Reveal.js CSS and JS links from a CDN.
Create a new slide for each heading starting with '#' or '##'.
Use the content under the headings as the slide content.
For content within backticks like `assets/image.jpg`, convert it to an `<img>` tag using the exact relative path inside the backticks.
For lists, convert them to `<ul>` or `<ol>` tags.
Return only the raw HTML code, without any explanations or markdown code blocks.

Markdown:
{markdown}""",
        input_variables=["markdown"],
    )

    # Create the generation chain
    generate_chain = prompt | llm | StrOutputParser()
    
    generated_html = generate_chain.invoke({"markdown": markdown})
    
    return {
        "presentation_html": generated_html,
        "revision_count": 0
    }

def evaluate_presentation_node(state: GraphState):
    """
    Evaluates the generated HTML using an LLM and provides feedback.
    """
    print("--- ğŸ§ Node: evaluate_presentation ---")
    html = state['presentation_html']
    
    prompt = PromptTemplate(
        template="""You are a web development expert who reviews code.
Review the following Reveal.js HTML presentation. Provide a short, bulleted list of actionable suggestions for improvement.
Focus on things like changing the theme (e.g., from 'black.css' to 'white.css' or 'sky.css'), improving the layout, or making the HTML title more specific based on the H1 tag.
If the presentation is good and needs no changes, respond with the exact phrase: 'No improvements needed.'.

HTML Code:
{html}""",
        input_variables=["html"],
    )

    # Create the evaluation chain
    evaluate_chain = prompt | llm | StrOutputParser()
    
    feedback = evaluate_chain.invoke({"html": html})
    
    print(f"Feedback received:\n{feedback}")
    
    return {"feedback": feedback}

def improve_presentation_node(state: GraphState):
    """
    Applies the feedback to improve the presentation using an LLM.
    """
    print("--- âœ¨ Node: improve_presentation ---")
    html = state['presentation_html']
    feedback = state['feedback']
    
    prompt = PromptTemplate(
        template="""You are a web development expert who applies feedback to code.
You are given an HTML file and a list of suggestions for improvement.
Apply the suggestions to the original HTML code and return ONLY the new, complete, and raw HTML file.
Do not add any commentary, explanations, or markdown code blocks.

Original HTML:
{html}

Suggestions:
{feedback}

Improved HTML:
""",
        input_variables=["html", "feedback"],
    )

    # Create the improvement chain
    improve_chain = prompt | llm | StrOutputParser()

    improved_html = improve_chain.invoke({"html": html, "feedback": feedback})
    
    revision_count = state.get('revision_count', 0) + 1
    
    return {
        "presentation_html": improved_html,
        "revision_count": revision_count
    }

# --- Conditional Edge Logic ---

def should_continue_edge(state: GraphState):
    """
    Determines whether to continue to the improvement step or finish.
    """
    print("--- ğŸ¤” Edge: should_continue ---")
    feedback = state['feedback']
    if "No improvements needed" in feedback:
        print("Decision: No improvements needed. Finishing.")
        return "end"
    else:
        print("Decision: Improvements suggested. Continuing to revision.")
        return "continue"

# --- Build the Graph ---
workflow = StateGraph(GraphState)

# Add the nodes
workflow.add_node("generator", generate_presentation_node)
workflow.add_node("evaluator", evaluate_presentation_node)
workflow.add_node("improver", improve_presentation_node)

# Set the entry point
workflow.set_entry_point("generator")

# Add the edges
workflow.add_edge("generator", "evaluator")
workflow.add_conditional_edges(
    "evaluator",
    should_continue_edge,
    {
        "continue": "improver",
        "end": END,
    },
)
# After one improvement, we'll end the process. You could loop back to the evaluator for more revisions.
workflow.add_edge("improver", END) 

# Compile the graph
app = workflow.compile()

# --- Run the Graph ---

# Sample Markdown Input from the user
markdown_input = """
# ä¸»ç¥·æ–‡ï¼ˆä¸Šï¼‰

## ä¸»ç¥·æ–‡
`assets/jesus_praying.jpg`

## å¤ä¹ :ç¥·å‘Šçš„ç›®çš„
1. ç›®çš„ä¸€ï¼šè£è€€ç¥
2. ç›®çš„äºŒï¼šå€Ÿç€æˆ‘ä»¬åœ¨ç¦éŸ³ä¸Šç»“æœå­ï¼Œè®©ä¸–äººè®¤è¯†ç¥
3. ç›®çš„ä¸‰ï¼šé¢å¯¹å±çµå¾æˆ˜

## å¤ä¹ ï¼šç¥·å‘Šçš„é™·é˜±
1. ä¾é ä¸ªäººæƒ…æ„Ÿ
2. å¾‹æ³•ä¸»ä¹‰
3. æ‡’æƒ°

## ç»æ–‡
- é©¬å¤ªç¦éŸ³6:5-15
5. â€œä½ ä»¬ç¥·å‘Šçš„æ—¶å€™ï¼Œä¸å¯åƒé‚£å‡å†’ä¸ºå–„çš„äººï¼Œçˆ±ç«™åœ¨ä¼šå ‚é‡Œå’Œåå­—è·¯å£ç¥·å‘Šï¼Œæ•…æ„è®©äººçœ‹è§ã€‚æˆ‘å®åœ¨å‘Šè¯‰ä½ ä»¬ï¼Œä»–ä»¬å·²ç»å¾—äº†ä»–ä»¬çš„èµèµã€‚ 
6. ä½ ç¥·å‘Šçš„æ—¶å€™ï¼Œè¦è¿›å…¥å†…å®¤ï¼Œå…³ä¸Šé—¨ï¼Œå‘é‚£åœ¨éšç§˜ä¸­çš„çˆ¶ç¥·å‘Šï¼›ä½ çˆ¶åœ¨éšç§˜ä¸­å¯Ÿçœ‹ï¼Œå¿…å°†èµèµä½ ã€‚ 
7. ä½ ä»¬ç¥·å‘Šï¼Œä¸å¯åƒå¤–é‚¦äººé‚£æ ·é‡å¤ä¸€äº›ç©ºè¯ï¼Œä»–ä»¬ä»¥ä¸ºè¯å¤šäº†å¿…è’™å‚å¬ã€‚ \
8. ä½ ä»¬ä¸å¯æ•ˆæ³•ä»–ä»¬ã€‚å› ä¸ºåœ¨ä½ ä»¬ç¥ˆæ±‚ä»¥å‰ï¼Œä½ ä»¬æ‰€éœ€è¦çš„ï¼Œä½ ä»¬çš„çˆ¶æ—©å·²çŸ¥é“äº†ã€‚â€
9. â€œæ‰€ä»¥ï¼Œä½ ä»¬è¦è¿™æ ·ç¥·å‘Šï¼šâ€˜æˆ‘ä»¬åœ¨å¤©ä¸Šçš„çˆ¶ï¼šæ„¿äººéƒ½å°Šä½ çš„åä¸ºåœ£ã€‚
10. æ„¿ä½ çš„å›½é™ä¸´ï¼›æ„¿ä½ çš„æ—¨æ„è¡Œåœ¨åœ°ä¸Šï¼Œå¦‚åŒè¡Œåœ¨å¤©ä¸Šã€‚
"""

# The initial state for the graph
initial_state = {"markdown_script": markdown_input}

# Invoke the graph and get the final state
final_state = app.invoke(initial_state, {"recursion_limit": 5})

# --- Final Output ---
final_html = final_state['presentation_html']

# Save the final HTML to a file to view it
output_filename = "presentation_ollama.html"
with open(output_filename, "w", encoding="utf-8") as f:
    f.write(final_html)

print(f"\nâœ… Final presentation saved to '{output_filename}'")
print(f"Total revisions: {final_state['revision_count']}")
